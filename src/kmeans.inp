function bundle set_bundle_and_get_defaults (const list xlist,
                                             bundle opts[null])
    /* Compile self bundle by merging eventual information
    from 'opts' bundle. */

    if !exists(opts)
        bundle opts = null
    endif

    bundle self = default_values(xlist)
    self = opts + self          # override defaults

    return self
end function


function bundle default_values (const list xlist)
    /* Set default values. */

    bundle self = null
    scalar self.error = FALSE
    scalar self.verbose = 1
    string self.initializer = "random"
    scalar self.n_draws = 10
    scalar self.max_iter = 300
    scalar self.tolerance = 1e-4
    string self.algorithm = "full"
    string self.distance_type = "euclidean"
    scalar self.nobs = $nobs

    # For kmeans_plot()
    scalar self.use_circles = FALSE
    scalar self.pointsize = 1.0

    return self
end function


function matrix initialize_clusters (const matrix features, const bundle self)
    /* Randomly assign observations to some initial cluster.
    return: series, Randomly assign 1 to n_cluster ID for each observation. */

    if self.initializer == "random"
        return mrandgen(i, 1, self.n_clusters, $nobs, 1)
    elif tolower(self.initializer) == "pca"
        bundle B = self
        matrix B.centroids = init_centroids_by_pca(features, B.n_clusters)
        list xlist = mat2list(features)
        matrix cluster_id = kmeans_predict(xlist, B)
        return cluster_id
    else
        funcerr "Initializer is not supported."
    endif
end function


function matrix init_centroids_by_pca (const matrix features, scalar n_clusters)
    /* Try to pick data points that are as far apart as possible by means of PCA.
    Idea borrowed from Jack Lucchetti.
    return: Matrix of centroids for each cluster (rows) and each feature (columns). */

    scalar n = rows(features)
    matrix mask = 1 + seq(0, (n_clusters - 1)) \
                  * floor((n - 1) / (n_clusters - 1))
    matrix f = princomp(features, 1, 1) ~ seq(1, n)'
    f = msortby(f, 1)
    mask = f[mask, 2]

    return features[mask,]
end function


function series kmeans_predict (const list xlist "Features",
                                const bundle self)
    /* Predict cluster belonging for a given model.
    return: Series with predicted cluster belongings. */

    errorif(sum(missing(xlist)), "Some features have missing values. Please drop these first.")

    matrix distances = distance({xlist}, self.distance_type, self.centroids)
    series cluster_id = iminr(distances)

    return cluster_id
end function


function void check_required_pkg_version (void)
    /* Check if installed dependencies fulfill version requirements. */

    pkg query PairPlot --quiet
    errorif($result.version < 0.8,\
            sprintf("Please update the 'PairPlot' package to at least version 0.8.\n\ The hansl command is 'pkg install PairPlot'")
            )
end function


function bundle kmeans_fit (const list xlist "Features",
                            const int n_clusters[2::2] "No. of clusters",
                            bundle opts[null] "Parameter bundle")
    /* Estimate clusters. */

    check_required_pkg_version()

    if !exists(opts)
        bundle opts = null
    endif

    errorif(sum(missing(xlist)),\
            "Some features have missing values. Please drop these first.")

    bundle self = set_bundle_and_get_defaults(xlist, opts)
    self.distance_type = tolower(self.distance_type)
    self.initializer = tolower(self.initializer)
    self.algorithm = tolower(self.algorithm)
    scalar self.n_clusters = n_clusters
    matrix features = {xlist}
    scalar self.within_variation_total = $huge
    scalar draw_id = 1
    matrix self.cluster_id = mshape(NA, $nobs, 1)
    matrix  self.distances = mshape(NA, $nobs, 1)

    loop self.n_draws  # evaluate several initial random draws of clusters
        if self.verbose == 2
            Info(sprintf("\nStart the %d-th random draw.", draw_id))
            flush
        endif

        bundle Tmp = compute_kmeans(self, features)

        if Tmp.within_variation_total < self.within_variation_total # select minimizing draw
            scalar self.within_variation_total = Tmp.within_variation_total
            matrix self.centroids = Tmp.centroids
            matrix cluster_id = Tmp.cluster_id
            matrix distances = Tmp.distances
        endif

        draw_id++
    endloop

    cnameset(self.centroids, varnames(xlist))

    matrix self.cluster_id = cluster_id
    matrix self.distances = distances
    add_variations(features, &self)

    return self
end function


function void add_variations (const matrix features, bundle *self)
    /* Add various variation statistics.
    return: void */

    self.total_ssq = sumc(distance(features,\
                                              self.distance_type,\
                                              meanc(features))\
                                    .^2)

    bundle B = within_cluster_variation(self.distances, self.cluster_id)
    scalar self.within_variation_avg = B["sum_of_avg_variation"]
    scalar self.within_variation_total = B["sum_of_total_variation"]
    scalar self.between_variation = self.total_ssq - self.within_variation_total
    scalar self.between_to_total_variation = self.between_variation / self.total_ssq
end function


function void kmeans_summary (const bundle self)
    /* Print summary after fitting. */

    print "************************************************"
    print "*** K-means unsupervised learning clustering ***"

    printf "\nParameters\n"
    printf "  No. of clusters: %d\n", self.n_clusters
    printf "  Distance type: '%s'\n", self.distance_type
    printf "  Algorithm: '%s'\n", self.algorithm
    printf "  Max. iterations: %d\n", self.max_iter
    #printf "  Actual iterations: %d\n", self.actual_iter
    printf "  No. of random draws: %d\n", self.n_draws
    printf "  Tolerance: %f\n", self.tolerance

    printf "\nEstimation results:\n"
    printf "  Total sum of squares: %.3f\n", self.total_ssq
    printf "  Total within-cluster sum of squares: %.3f\n", self.within_variation_total
    printf "  Weighted total within-cluster sum of squares: %.3f\n", self.within_variation_avg
    printf "  Between cluster sum of squares: %.3f\n", self.between_variation
    printf "  (Between / Total): %.3f pct.\n", (self.between_to_total_variation * 100)
    print "************************************************"
end function


function void kmeans_plot (const list xlist, bundle self[null])
    /* Plot clusters in 2-dimensions. */

    if !exists(PlotOpts)
        bundle PlotOpts = null
    endif

    PlotOpts = PlotOpts + self          # override defaults
    string PlotOpts.filename = inbundle(PlotOpts, "filename") ? PlotOpts.filename : "display"
    series factor = self.cluster_id

    PairPlot(xlist, factor, PlotOpts)

    Info("Finished plotting.")
end function


function bundle compute_kmeans (const bundle self, const matrix features)
    /* Actual computation of kmeans. Identify clusters.
    return: bundle, output for a given random draw of cluster association. */

    bundle Model
    matrix cluster_id = initialize_clusters(features, self)
    scalar n_clusters = rows(values(cluster_id))
    scalar iter = 1
    matrix distances = mshape($huge, rows(features), n_clusters)
    scalar inertia = $huge
    scalar inertia_new = inertia

    loop while iter <= self.max_iter
        matrix centroids = centroids(features, cluster_id)
        matrix distances_new = distance(features, self.distance_type, centroids)
        matrix cluster_id_new = iminr(distances_new)

        if rows(values(cluster_id_new)) == n_clusters  # check + update
            matrix centroids = centroids(features, cluster_id_new)
            cluster_id = cluster_id_new
            matrix distances = minr(distances_new)  # select minimum from all

            iter++
        else
            Warn(sprintf("Some assumed cluster has no observations. Stop searching after %d iterations.", iter))
            break
        endif

        inertia_new = within_cluster_variation(distances, cluster_id)["sum_of_total_variation"]
        inertia_delta = inertia - inertia_new
        inertia = inertia_new

        if inertia_delta >= 0 && inertia_delta < self.tolerance
            if self.verbose == 2
                Info(sprintf("Converged after %d out of %d iterations (within total variation = %.5f).", iter, self.max_iter, inertia))
                flush
            endif
            break
        endif
    endloop

    matrix Model.distances = distances
    scalar Model.within_variation_total = inertia
    matrix Model.cluster_id = cluster_id
    matrix Model.centroids = centroids

    return Model
end function


function bundle within_cluster_variation (const matrix distances,
                                          const matrix cluster_id)
    /* Compute the sum of the (average) squared distances across all clusters.

    "distances" already refers to some computed distance from the centroid, for instance $(x_{ij} - xbar_{ij})^2$ in case of the Euclidean distance. But it could also be some other distance measure.
    The following definition is equal to the within-cluster variation as defined in James et al. "An Introduction to Statistical Learning", p. 387. */

    scalar n_clusters = max(cluster_id)
    matrix d2 = distances.^2
    bundle B = _(sum_of_avg_variation = 0,\
                 sum_of_total_variation = sum(d2))

    loop i=1..n_clusters
        matrix mask = (cluster_id .= $i)
        scalar n = sum(mask)
        B.sum_of_avg_variation += sum(selifr(d2, mask).^2) * (1 / n)
    endloop

    return B
end function


function matrix centroids (const matrix features,
                           const matrix cluster_id)
    /* Compute centroids (means) for each cluster.
    return: "n_clusters by 1+cols(features)" matrix, The i-th row corresponds to the i-th cluster; each column refers to the centroid (mean) value for each respective feature. */

    scalar n_clusters = max(cluster_id)
    matrix centroids = mshape(NA, n_clusters, cols(features))
    strings row_labels = array(n_clusters)

    loop i=1..n_clusters
        matrix mask = (cluster_id .= $i)
        centroids[i,] = meanc(selifr(features, mask))
        row_labels[i] = sprintf("Centroid=%d", $i)
    endloop

    rnameset(centroids, row_labels)

    return centroids
end function
